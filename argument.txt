En primera instancia puede parecer un diseño muy extraño, carente de toda elegancia, sin embargo permita me explicar el razonamiento que dio origen a este montaje.

En primer lugar había considerado usar apache kafka para comunicar los dos micro-servicios, sin embargo dada la naturaleza volátil del tamaño del fichero de entrada y mas aun de la incierta demora que podría acarrear el consultar cientos de miles o millones de coordenadas frente al API de postcodes.io; se hizo evidente que el sistema debía trabajar de forma asíncrona aprovechándose lo máximo posible del trabajo en segundo plano para hacer su labor.

Por fortuna, al usuario (quien sube el fichero original) no le interesan los datos consultados, tan solo se preocupa por la integridad del fichero suministrado. Con esto en mente,  la solución debía priorizar el entregar una respuesta lo mas sencilla y rápida posible, al proceso inicial de recibir y analizar el fichero, para ya luego tomarse todo el tiempo del mundo en hacer el tedioso proceso de consulta y almacenamiento.

Dado que el tamaño del fichero no esta limitado, y que por tanto puede ser en efecto muy grande, decidí separa el procesado del archivo en dos partes, la recepción inicial tal cual, cuya demora depende principalmente de la capacidad de transferencia de datos entre el cliente y el servicio, y que difícilmente puede mejorarse. Y luego ya el procesado lógico de su contenido, ofreciéndole al cliente una primer respuesta simple que le permitiese desligarse de la espera y que a su vez le otorgara un método para consultar el estado de la segunda etapa. Es por eso que la respuesta del “endpoit” se obtiene en dos partes.

Ahora bien como he mencionado antes, el tamaño del fichero es un gran problema y ya que RabbitMQ recomienda no exceder los 128Mb de datos por mensaje (en el mejor de los casos), decidí usar REDIS como broker para esta primer tarea en segundo plano.

Para transportar los datos del dominio del “enpoint” al del “consumer”, decidí crear una segunda tarea en background por dos razones, la primera que el API de postcodes.io admite como máximo consultas de 100 coordenadas, así que me venia bien separar el grueso del fichero en unidades mas manejables. Y la segunda, que para la comunicación entre los micro-servicios, sí que viene mejor un servicio de colas de mensajes como Kafka o RabbitMQ y no REDIS, y cómo ya mencione antes en estos sistemas es mucho mejor tener numerosos mensajes pequeños que no uno muy grande.

Abría montado kafka para esta tarea, sobretodo por su capacidad de comprimir al vuelo, pero ya que tenia claro que iba a usar otra tarea de Celery en el “consumer”, que esta vez sí sería con RabbitMQ como broker y que contando la base de datos sql, ya montaba 3 servicios de apoyo, pues decidí salir al paso con RabbitMQ para comunicar los micro-servicios.

En ultima instancia me interesaban dos cosas, la primera hacer la menor cantidad de llamadas posibles al API de postcodes, y la segunda, evitar tener que hacer consultas SQL para controlar la repetición de datos. Afortunadamente al montar REDIS ya tenia una forma muy sencilla de hacer una cache de eliminación, que básicamente es un registro rápido que me permite saber que coordenadas ya he consultado, almacenado o descartado para no tener que ocuparme mas de ellas y poderlas descartar en primera instancia.

Por ultimo el almacenamiento persistente en SQL, fue una decisión mas de costumbre que de cualquier otra cosa, pues seguro que este tipo de datos iría bien en una base de datos documental o similares, pero dado que no son datos complejos ni su estructura es muy enrevesada, consideré que una base de datos tradicional sería suficiente.

Ahora bien, seguro que se alguien se pregunta porque solo hay un contenedor de REDIS y uno de RabbitMQ, si uso ambos servicios para dos tareas… no sería mejor entonces tener dos instancias, una para cada labor, y sí sería mejor, pero tampoco es algo determinante, la arquitectura en si puede escalarse a N workers de Celery, N colas de RabbitMQ o N instancias de REDIS, sin mayores complicaciones, a la hora de poner este sistema en producción, pero para cumplir los objetivos de este punto, la implementación actual es apenas suficiente.